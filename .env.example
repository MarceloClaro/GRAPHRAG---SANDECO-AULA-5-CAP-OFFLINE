# ============================================
# GraphRAG Pipeline - Configuração Ambiental
# ============================================
# Copie este arquivo para .env.local e configure

# ============================================
# GOOGLE GEMINI (Recomendado)
# ============================================
# Obter API key em: https://ai.google.dev
# Deixe em branco para usar apenas Ollama local

VITE_GEMINI_API_KEY=AIzaSy...

# ============================================
# OLLAMA LOCAL (Gratuito, Offline)
# ============================================
# Instalar: https://ollama.ai
# Antes de usar: ollama serve
# Modelos disponíveis: llama3.2, mistral, phi3, qwen, etc

VITE_OLLAMA_ENDPOINT=http://localhost:11434
VITE_OLLAMA_MODEL=llama3.2:3b
VITE_OLLAMA_EMBEDDING_MODEL=nomic-embed-text
